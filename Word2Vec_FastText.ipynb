{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMib/ikz2ya2xkNpdbb2/Wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamzaAnjum15/NLP/blob/main/Word2Vec_FastText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec is a neural network-based technique to convert words into vectors, where words with similar meanings have similar vector representations. These vectors are used in many natural language processing (NLP) applications, such as sentiment analysis and machine translation. Word2Vec essentially helps in mapping words into a numerical format that can be fed into machine learning models.\n",
        "\n",
        "There are two main types of Word2Vec models:\n",
        "\n",
        "CBOW (Continuous Bag of Words): Predicts the target word from surrounding context words.\n",
        "Skip-gram: Predicts surrounding context words given a target word.\n"
      ],
      "metadata": {
        "id": "xDPQV3Z5Z1a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-JPvQASZ2iM",
        "outputId": "e913000e-d2b0-42e1-ac14-3a3246e48b80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "metadata": {
        "id": "uR8NVdkIZ6ni"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sentences = [\n",
        "    \"I love natural language processing and machine learning\",\n",
        "    \"Word2Vec helps in understanding word similarities\",\n",
        "    \"Machine learning is fun and interesting\",\n",
        "    \"Natural language processing is a part of machine learning\",\n",
        "    \"I enjoy learning new things in artificial intelligence\"\n",
        "]\n",
        "\n",
        "# Tokenize each sentence\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "print(tokenized_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN5Av0tdaCx_",
        "outputId": "d8787148-4401-4512-8f36-f197042a9e08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'love', 'natural', 'language', 'processing', 'and', 'machine', 'learning'], ['word2vec', 'helps', 'in', 'understanding', 'word', 'similarities'], ['machine', 'learning', 'is', 'fun', 'and', 'interesting'], ['natural', 'language', 'processing', 'is', 'a', 'part', 'of', 'machine', 'learning'], ['i', 'enjoy', 'learning', 'new', 'things', 'in', 'artificial', 'intelligence']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vector_size=50: Sets the vector dimension size to 50 (you can adjust it).\n",
        "window=3: Specifies that we want to consider a window of 3 words around the target word.\n",
        "min_count=1: Ignores words that appear less than once.\n",
        "sg=0: Sets the model to use CBOW (if sg=1, it uses Skip-gram)."
      ],
      "metadata": {
        "id": "9ajwDMpJa18g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=50, window=3, min_count=1, sg=0)\n"
      ],
      "metadata": {
        "id": "zH7BlcUdaOEo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5f_iDL8Aa1P5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Kg9QTMNAa0Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get vector for a word\n",
        "word_vector = model.wv['machine']\n",
        "print(word_vector)\n",
        "#This will print out a 50-dimensional vector representation for the word \"machine\".\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW7wTAYma9d3",
        "outputId": "522241cd-c84c-4741-e305-86b63ad85097"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01631348  0.00898898 -0.0082744   0.00164721  0.01700014 -0.00892164\n",
            "  0.00903623 -0.01357399 -0.00709444  0.01879727 -0.00316053  0.00064218\n",
            " -0.0082786  -0.01536866 -0.00301601  0.00494228 -0.00177495  0.01106751\n",
            " -0.00548537  0.00452524  0.01090642  0.01668959 -0.00290629 -0.01841395\n",
            "  0.00873797  0.00114173  0.01487998 -0.00163029 -0.00527568 -0.01750633\n",
            " -0.00171392  0.00565271  0.01080288  0.01410596 -0.01140395  0.00371848\n",
            "  0.01217604 -0.00959917 -0.00621352  0.01359702  0.003265    0.00037837\n",
            "  0.00695048  0.00043391  0.01923932  0.01012449 -0.01783132 -0.01408467\n",
            "  0.00180031  0.01278293]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find words similar to 'learning'\n",
        "similar_words = model.wv.most_similar('learning', topn=5)\n",
        "print(similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR5QIqc-bDin",
        "outputId": "81ae8a78-4982-4b92-9d4c-1dd74186df92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('a', 0.2707342505455017), ('artificial', 0.21156349778175354), ('things', 0.18648891150951385), ('word2vec', 0.1672801673412323), ('new', 0.16135866940021515)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Word Vector for 'data': {word_vector[:5]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruUt1pCVbQeY",
        "outputId": "fbb113c8-58ad-4b9d-a9d5-4b0e556e3b42"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Vector for 'data': [-0.01631348  0.00898898 -0.0082744   0.00164721  0.01700014]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample corpus (list of sentences)\n",
        "sentences = [\n",
        "    \"I love natural language processing.\",\n",
        "    \"Natural language processing is fun.\",\n",
        "    \"I enjoy learning about data science.\",\n",
        "    \"Machine learning is a part of data science.\"\n",
        "]\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "# Train the FastText model\n",
        "model_fasttext = FastText(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1)\n",
        "\n",
        "# Get the vector for a specific word\n",
        "word_vector_fasttext = model_fasttext.wv['data']\n",
        "\n",
        "# Print the word vector for 'data' (first 5 dimensions)\n",
        "print(f\"FastText Word Vector for 'data': {word_vector_fasttext[:5]}\")\n",
        "\n",
        "# Find similar words to 'data'\n",
        "similar_words_fasttext = model_fasttext.wv.most_similar('data')\n",
        "print(\"\\nWords similar to 'data' using FastText:\", similar_words_fasttext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUQ1VU9Jba5L",
        "outputId": "0988c696-3dd6-4aa3-e358-6fb3de1cd193"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText Word Vector for 'data': [-0.00014643  0.00029048  0.00104975 -0.00074337 -0.00244071]\n",
            "\n",
            "Words similar to 'data' using FastText: [('machine', 0.2867852747440338), ('science', 0.10667353123426437), ('is', 0.09705585241317749), ('fun', 0.09495128691196442), ('a', 0.0866626650094986), ('i', 0.08312514424324036), ('of', 0.04464837163686752), ('natural', 0.028660064563155174), ('about', 0.0029689136426895857), ('language', -0.02337067760527134)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d8EejjgecNCG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}